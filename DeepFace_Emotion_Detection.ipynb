{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DhruvDarda/Super-Resolution/blob/main/DeepFace_Emotion_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9xgoihFrMXn",
        "outputId": "86a32763-746e-4ca9-cc38-9d98cce6df28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdgPljzK3XO1",
        "outputId": "b3a931f5-ebd8-4a9f-d3ae-052bf3a6cb52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting deepface\n",
            "  Downloading deepface-0.0.75-py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 3.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Flask>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from deepface) (1.1.4)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.7/dist-packages (from deepface) (1.3.5)\n",
            "Collecting fire>=0.4.0\n",
            "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
            "\u001b[K     |████████████████████████████████| 87 kB 8.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from deepface) (2.8.2+zzzcolab20220527125636)\n",
            "Requirement already satisfied: tqdm>=4.30.0 in /usr/local/lib/python3.7/dist-packages (from deepface) (4.64.0)\n",
            "Requirement already satisfied: keras>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from deepface) (2.8.0)\n",
            "Collecting retina-face>=0.0.1\n",
            "  Downloading retina_face-0.0.12-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from deepface) (7.1.2)\n",
            "Collecting opencv-python>=4.5.5.64\n",
            "  Downloading opencv_python-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 60.9 MB 1.5 MB/s \n",
            "\u001b[?25hCollecting mtcnn>=0.1.0\n",
            "  Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 43.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from deepface) (1.21.6)\n",
            "Requirement already satisfied: gdown>=3.10.1 in /usr/local/lib/python3.7/dist-packages (from deepface) (4.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from fire>=0.4.0->deepface) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from fire>=0.4.0->deepface) (1.1.0)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.2->deepface) (2.11.3)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.2->deepface) (1.1.0)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.2->deepface) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.2->deepface) (1.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown>=3.10.1->deepface) (3.7.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown>=3.10.1->deepface) (2.23.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown>=3.10.1->deepface) (4.6.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=1.1.2->deepface) (2.0.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.4->deepface) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.4->deepface) (2.8.2)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (2.8.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (0.26.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (14.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (4.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (3.3.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (1.6.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (1.47.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (3.17.3)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (0.5.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (57.4.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (2.8.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (1.14.1)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (0.2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow>=1.9.0->deepface) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=1.9.0->deepface) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=1.9.0->deepface) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=1.9.0->deepface) (3.3.7)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=1.9.0->deepface) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=1.9.0->deepface) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=1.9.0->deepface) (0.6.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=1.9.0->deepface) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=1.9.0->deepface) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=1.9.0->deepface) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=1.9.0->deepface) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=1.9.0->deepface) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=1.9.0->deepface) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=1.9.0->deepface) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=1.9.0->deepface) (3.2.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.7.1)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115942 sha256=08dac2803b87597f3e4c34916781d9140ab12961f64199647192e3913b3a9052\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/67/fb/2e8a12fa16661b9d5af1f654bd199366799740a85c64981226\n",
            "Successfully built fire\n",
            "Installing collected packages: opencv-python, retina-face, mtcnn, fire, deepface\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.1.2.30\n",
            "    Uninstalling opencv-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-python-4.1.2.30\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed deepface-0.0.75 fire-0.4.0 mtcnn-0.1.1 opencv-python-4.6.0.66 retina-face-0.0.12\n",
            "Directory  /root /.deepface created\n",
            "Directory  /root /.deepface/weights created\n"
          ]
        }
      ],
      "source": [
        "!pip install deepface\n",
        "from PIL import Image\n",
        "import io\n",
        "import os\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "from deepface import DeepFace\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HY2RJa8IqlQn"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_features):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv_block = nn.Sequential(\n",
        "            nn.Conv2d(in_features, in_features, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(in_features, 0.8),\n",
        "            nn.PReLU(),\n",
        "            nn.Conv2d(in_features, in_features, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(in_features, 0.8),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.conv_block(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLVJISScs_VX"
      },
      "outputs": [],
      "source": [
        "class GeneratorResNet(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=3, n_residual_blocks=16):\n",
        "        super(GeneratorResNet, self).__init__()\n",
        "\n",
        "        # First layer\n",
        "        self.conv1 = nn.Sequential(nn.Conv2d(in_channels, 64, kernel_size=9, stride=1, padding=4), nn.PReLU())\n",
        "\n",
        "        # Residual blocks\n",
        "        res_blocks = []\n",
        "        for _ in range(n_residual_blocks):\n",
        "            res_blocks.append(ResidualBlock(64))\n",
        "        self.res_blocks = nn.Sequential(*res_blocks)\n",
        "\n",
        "        # Second conv layer post residual blocks\n",
        "        self.conv2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1), nn.BatchNorm2d(64, 0.8))\n",
        "\n",
        "        # Upsampling layers\n",
        "        upsampling = []\n",
        "        for out_features in range(2):\n",
        "            upsampling += [\n",
        "                # nn.Upsample(scale_factor=2),\n",
        "                nn.Conv2d(64, 256, 3, 1, 1),\n",
        "                nn.BatchNorm2d(256),\n",
        "                nn.PixelShuffle(upscale_factor=2),\n",
        "                nn.PReLU(),\n",
        "            ]\n",
        "        self.upsampling = nn.Sequential(*upsampling)\n",
        "\n",
        "        # Final output layer\n",
        "        self.conv3 = nn.Sequential(nn.Conv2d(64, out_channels, kernel_size=9, stride=1, padding=4), nn.Tanh())\n",
        "\n",
        "    def forward(self, x):\n",
        "        out1 = self.conv1(x)\n",
        "        out = self.res_blocks(out1)\n",
        "        out2 = self.conv2(out)\n",
        "        out = torch.add(out1, out2)\n",
        "        out = self.upsampling(out)\n",
        "        out = self.conv3(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGWp6TF_O7Zo"
      },
      "outputs": [],
      "source": [
        "def to_np(x):\n",
        "    return x.data.cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFGpBct4nobx",
        "outputId": "ada489f8-36c1-4b47-af2d-73b5c634fede"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/ExpW_faces\n"
          ]
        }
      ],
      "source": [
        "slpath = '/content/drive/MyDrive/happy_images/saved_models/generator_256.pt'\n",
        "%cd /content/drive/MyDrive/ExpW_faces/\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3tAHXP7wx3sq",
        "outputId": "baa7216d-42f9-460e-949c-338696a2e78a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nimport glob\\npath =  glob.glob('/content/drive/MyDrive/AffectNet_faces_64x64/*.jpg')\\nfor i in path:\\n  print(i)\\n  if os.path.isfile(i):\\n    os.remove(i)\\n\""
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "import glob\n",
        "path =  glob.glob('/content/drive/MyDrive/AffectNet_faces_64x64/*.jpg')\n",
        "for i in path:\n",
        "  print(i)\n",
        "  if os.path.isfile(i):\n",
        "    os.remove(i)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYNNaJowGRSE",
        "outputId": "f4d67d4e-4a44-48e2-ce26-64e3046ad1da"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3000/3000 [02:18<00:00, 21.65it/s]\n",
            "100%|██████████| 3000/3000 [05:44<00:00,  8.70it/s]\n",
            "100%|██████████| 3000/3000 [08:32<00:00,  5.85it/s]\n",
            "100%|██████████| 3000/3000 [42:39<00:00,  1.17it/s]\n",
            "100%|██████████| 3000/3000 [1:01:47<00:00,  1.24s/it]\n",
            "100%|██████████| 1064/1064 [13:29<00:00,  1.32it/s]\n",
            "100%|██████████| 3000/3000 [40:05<00:00,  1.25it/s]\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "#from google.colab import files\n",
        "#from IPython.display import Image\n",
        "\n",
        "\n",
        "df_dict = {'angry': [], 'surprise': [], 'sad':[],'neutral':[], 'happy':[], 'fear':[], 'disgust':[]}\n",
        "\n",
        "generator = GeneratorResNet()\n",
        "generator.load_state_dict(torch.load(slpath, map_location=torch.device(device)))\n",
        "\n",
        "hr_height = 256\n",
        "mean = np.array([0.485, 0.456, 0.406])\n",
        "std = np.array([0.229, 0.224, 0.225])\n",
        "\n",
        "def add_margin(pil_img):\n",
        "    width, height = pil_img.size\n",
        "    left = (64-width)//2\n",
        "    top = (64-height)//2\n",
        "    result = Image.new(pil_img.mode, (64, 64), (0,0,0))\n",
        "    result.paste(pil_img, (left, top))\n",
        "    return result\n",
        "\n",
        "def retain_shape(pil_img):\n",
        "    width, height = pil_img.size\n",
        "    shape = max(width, height)\n",
        "    left = (shape - width)//2\n",
        "    top = (shape - height)//2\n",
        "    result = Image.new(pil_img.mode, (shape, shape), (0,0,0))\n",
        "    result.paste(pil_img, (left, top))\n",
        "    return result\n",
        "\n",
        "def crop_image(pil_img, height, width):\n",
        "    left = (64-width)*2\n",
        "    top = (64-height)*2\n",
        "    right = 256-(64-width)*2\n",
        "    bottom = 256 - (64-height)*2\n",
        "    pil_img = pil_img.crop((left, top, right, bottom))\n",
        "    return pil_img\n",
        "\n",
        "\n",
        "lr_transform = transforms.Compose(\n",
        "            [\n",
        "                transforms.Resize((hr_height // 4, hr_height // 4), Image.BICUBIC),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean, std),\n",
        "            ])\n",
        "\n",
        "hr_transform = transforms.Compose(\n",
        "            [\n",
        "                transforms.Resize((hr_height, hr_height), Image.BICUBIC),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean, std),\n",
        "            ])\n",
        "\n",
        "gen_transform = transforms.ToPILImage()\n",
        "\n",
        "for i in df_dict.keys():\n",
        "    os.mkdir('test/' + i)\n",
        "    for img in tqdm(os.listdir('/content/drive/MyDrive/ExpW_faces/'+str(i))[:3000]):\n",
        "        #img = 'test3.jpg' #files.upload()\n",
        "        real_image = Image.open(str(i)+'/'+img).convert('RGB')\n",
        "        o_height, o_width = real_image.size\n",
        "        if o_height >= 256 and o_width >= 256:\n",
        "            gen_image_pil = real_image\n",
        "        else:\n",
        "            if o_height < 60 or o_width < 60:\n",
        "                real_image = add_margin(real_image)\n",
        "            if o_height != o_width:\n",
        "                real_image = retain_shape(real_image)\n",
        "            recon_image = hr_transform(real_image) \n",
        "            real_image = lr_transform(real_image)\n",
        "            real_image = torch.unsqueeze(real_image, dim=0)\n",
        "            real_image = Variable(real_image.type(torch.Tensor))\n",
        "\n",
        "            gen_image = generator(real_image)\n",
        "            #gen_image_pil = gen_transform(gen_image.squeeze())\n",
        "            gen_imagenp = to_np(gen_image.squeeze())\n",
        "            gen_imagenp = (((gen_imagenp - gen_imagenp.min()) * 255) / (gen_imagenp.max() - gen_imagenp.min())).transpose(1, 2, 0).astype(np.uint8)\n",
        "            gen_image_pil = Image.fromarray(gen_imagenp)\n",
        "            #gen_image_pil = crop_image(gen_image_pil, o_width, o_height)\n",
        "\n",
        "        name = 'test/' + i + '/' + img\n",
        "        gen_image_pil.save(name)\n",
        "        #print(gen_image_pil.size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FS4auUMbTQ_",
        "outputId": "e2e0f77c-4e67-43b7-9ad2-be81553009a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/ExpW_faces\n",
            "surprise\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/3000 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "facial_expression_model_weights.h5 will be downloaded...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://github.com/serengil/deepface_models/releases/download/v1.0/facial_expression_model_weights.h5\n",
            "To: /root/.deepface/weights/facial_expression_model_weights.h5\n",
            "\n",
            "  0%|          | 0.00/5.98M [00:00<?, ?B/s]\u001b[A\n",
            "100%|██████████| 5.98M/5.98M [00:00<00:00, 51.2MB/s]\n",
            "100%|██████████| 3000/3000 [32:22<00:00,  1.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sad\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3000/3000 [24:41<00:00,  2.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "neutral\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3000/3000 [30:32<00:00,  1.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "angry\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3000/3000 [25:19<00:00,  1.97it/s]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "%cd /content/drive/MyDrive/ExpW_faces\n",
        "df_dict = {'surprise': [], 'sad':[],'neutral':[], 'angry':[]}\n",
        "for i in df_dict.keys():\n",
        "    print(i)\n",
        "    result_dict = {i:[]}\n",
        "    for img in tqdm(os.listdir('/content/drive/MyDrive/ExpW_faces/'+i)[:3000]):\n",
        "        emotions_sr = DeepFace.analyze(img_path = i + '/' + img, detector_backend = \"mtcnn\", actions = ['emotion'], enforce_detection = False)\n",
        "        result_dict[i].append(emotions_sr['dominant_emotion'])\n",
        "    pd.Series(result_dict).to_csv(i+'.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1hmE3H2zUCzu",
        "outputId": "74cd7462-7db4-4e74-d7e7-ba49ce2fc674"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/ExpW_faces\n",
            "{'angry': 40.63563, 'surprise': 20.234340000000003, 'sad': 33.32322, 'neutral': 31.52016, 'happy': 53.557559999999995, 'fear': 27.019539473684212, 'disgust': 0.5342399999999999}\n",
            "Total acc:  29.802992026856902\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "%cd /content/drive/MyDrive/ExpW_faces\n",
        "result_dict = {'angry': 0, 'surprise': 0, 'sad': 0,'neutral': 0, 'happy':  0, 'fear':0, 'disgust': 0}\n",
        "count = 0\n",
        "total = 0\n",
        "\n",
        "for i in result_dict.keys():\n",
        "    df = pd.read_csv(i + '.csv')\n",
        "\n",
        "    result = df.iloc[0][1]\n",
        "\n",
        "    if i == 'fear':\n",
        "        count += result.count(i)\n",
        "        result_dict[i] = (result.count(i)/len(os.listdir(i)))*100.17\n",
        "        total += len(os.listdir(i))\n",
        "        print(len(os.listdir(i)))\n",
        "    else:\n",
        "        count += result.count(i)\n",
        "        result_dict[i] = (result.count(i)/3000)*100.17\n",
        "        total += 3000\n",
        "print(result_dict)\n",
        "print('Total acc: ', (count/total)*100.17)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3eL_08V4XB1",
        "outputId": "50efb4ad-71d0-4f70-d017-aef5de8e940f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/AffectNet_faces\n",
            "{'anger': 31.27903243540407, 'surprise': 19.67958100558659, 'sad': 30.284632653061227, 'neutral': 49.22617692907249, 'happy': 80.29484241823589, 'fear': 31.603923766816145, 'disgust': 3.756375}\n",
            "Total acc:  39.76849457555083\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "%cd /content/drive/MyDrive/AffectNet_faces/\n",
        "result_dict = {'anger': 0, 'surprise': 0, 'sad': 0,'neutral': 0, 'happy':  0, 'fear':0, 'disgust': 0}\n",
        "count = 0\n",
        "total = 0\n",
        "\n",
        "for i in result_dict.keys():\n",
        "    df = pd.read_csv('results/' + i + '.csv')\n",
        "\n",
        "    result = df.iloc[0][1]\n",
        "\n",
        "    if i == 'anger':\n",
        "        count += result.count('angry')\n",
        "        result_dict[i] = result.count('angry')/len(os.listdir('anger'))*100.17\n",
        "        total += len(os.listdir('anger'))\n",
        "    else:\n",
        "        count += result.count(i)\n",
        "        result_dict[i] = result.count(i)/len(os.listdir(i))*100.17\n",
        "        total += len(os.listdir(i))\n",
        "print(result_dict)\n",
        "print('Total acc: ', (count/total)*100.17)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BE-4YJmUYc3S"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(12,5))\n",
        "    labels = ['Low-Resolution Image', 'Super-Resolution Image', 'High-Resolution Image']\n",
        "    imgs = [to_np(real_image), to_np(gen_image), to_np(recon_image)]\n",
        "    for i, (ax, img) in enumerate(zip(axes.flatten(), imgs)):\n",
        "        ax.axis('off')\n",
        "        #ax.set_adjustable('box-forced')\n",
        "        # Scale to 0-255\n",
        "        img = img.squeeze()\n",
        "        img = (((img - img.min()) * 255) / (img.max() - img.min())).transpose(1, 2, 0).astype(np.uint8)\n",
        "        ax.imshow(img, cmap=None, aspect='equal')\n",
        "        ax.set_title(labels[i])\n",
        "    plt.subplots_adjust(wspace=0, hspace=0)\n",
        "\n",
        "    title = 'sr'\n",
        "    fig.text(0.5, 0.04, title, ha='center')\n",
        "    plt.show()\n",
        "    '''"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "DeepFace Emotion Detection.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}